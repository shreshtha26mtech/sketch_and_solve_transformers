{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MKUW4gwm3GR"
      },
      "outputs": [],
      "source": [
        "#importing all the neccesary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peiZGHBinAU6"
      },
      "source": [
        "**Faster Matrix Multiplication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwNR2-Zvwel2"
      },
      "source": [
        "The idea behind this paper is to use sampling methods as opposed to the traditional linear methods for sampling like count sketch or J-L lemma which dont need to look at the data to reduce the dimensions of the original matrix or to just make the matrix multiplication faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTF1C6n8wzD8"
      },
      "source": [
        "The given below code implements the coordinated sampling method shown in the paper by christopher musco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OO2UaJYbqNA"
      },
      "source": [
        "**Coordinated Sampling**\n",
        "#### **Input:**\n",
        "- Matrix \\( A \\) of size \\( n \\times d \\).\n",
        "- Random seeds.\n",
        "- Number of row samples, \\( k \\).\n",
        "\n",
        "#### **Output:**\n",
        "- Sketch \\( S(A) = \\{ I_A, V_A, \\ta \\} \\), where:\n",
        "  - \\( I_A \\) is a subset of row indices from \\( \\{1, ..., n\\} \\).\n",
        "  - \\( V_A \\) contains \\( A_i \\) for all \\( i \\in I_A \\).\n",
        "\n",
        "#### **Steps:**\n",
        "1. Use random seeds to select a uniformly random hash function:\n",
        "   $$\n",
        "   h: \\{1, ..., n\\} \\to [0,1]\n",
        "   $$\n",
        "2. Initialize \\( I_A \\) and \\( V_A \\) as empty lists.\n",
        "3. Compute rank for each row \\( A_i \\) (if \\( A_i !=0 \\)):\n",
        "   $$\n",
        "   R_i = \\frac{h(i)}{\\|A_i\\|_2^2}\n",
        "   $$\n",
        "4. Set:\n",
        "   - ta=equal to the \\((k+1)\\)st smallest value of \\( R_i \\), or\n",
        "   - \\( ta = infinty \\) if \\( A \\) has fewer than \\( k+1 \\) nonzero rows.\n",
        "5. For each \\( i \\) where \\( A_i \\neq 0 \\):\n",
        "   - If \\( R_i < \\tau_A \\):\n",
        "     - Append \\( i \\) to \\( I_A \\).\n",
        "     - Append \\( A_i \\) to \\( V_A \\).\n",
        "6. Return:\n",
        "   $$\n",
        "   S(A) = \\{ I_A, V_A, ta\\}\n",
        "   $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJtYWYFUh_2r"
      },
      "outputs": [],
      "source": [
        "hash = np.random.uniform(0, 1, size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U_PolQUw-8z"
      },
      "outputs": [],
      "source": [
        "def coordinated_sampling(A, k):\n",
        "    # here k are the number of parameters\n",
        "    # A is the original matrix of size n x d\n",
        "    n, d = np.shape(A)\n",
        "    #setting the shared random seed\n",
        "    random.seed(42)\n",
        "\n",
        "    # hash function which assigns the values between 0 and 1 randomly to the n numbers\n",
        "    hash_function = hash\n",
        "\n",
        "    # i_a to store the indexes and va to store the values\n",
        "    i_a = []\n",
        "    v_a = []\n",
        "\n",
        "    # Calculating ri\n",
        "    r = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        norm = np.linalg.norm(A[i])\n",
        "        if norm != 0:\n",
        "            r[i] = hash[i] / (norm ** 2)\n",
        "        else:\n",
        "            r[i] = np.inf\n",
        "\n",
        "    # Get the (k+1)-th smallest rank as the threshold\n",
        "    r_sorted = np.sort(r)\n",
        "    threshold = r_sorted[k] if k < n else np.inf\n",
        "\n",
        "    # Sample rows based on the threshold\n",
        "    for i in range(n):\n",
        "        if r[i] < threshold:\n",
        "            i_a.append(i)\n",
        "            v_a.append(A[i])\n",
        "\n",
        "    # the sketch matrix\n",
        "    sketch = {\n",
        "        'IA': np.array(i_a),\n",
        "        'VA': np.array(v_a),\n",
        "        'ta': threshold\n",
        "    }\n",
        "    return sketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZTiC1Jc2ThZ"
      },
      "outputs": [],
      "source": [
        "#creating the matrix a\n",
        "A=np.random.randn(10000,10000)\n",
        "sketch_a=coordinated_sampling(A,25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VyVpoJF8RjD"
      },
      "outputs": [],
      "source": [
        "#creating the matrix b\n",
        "B=np.random.randn(10000,10000)\n",
        "sketch_b=coordinated_sampling(B,25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXqJC9db8owL"
      },
      "source": [
        "Now that we are done with sampling and creating sketches of the original matrices, we will use this to create a matrix product approximate and see the mean variance and the norm error for the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QMURlLB9Y_Z",
        "outputId": "0ce33c04-9ebb-4c54-ec8e-eee4a7642e73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.06368101,  0.83262193, -0.79517654, ..., -0.86681992,\n",
              "         0.49285885,  0.88084319],\n",
              "       [-0.31625729, -0.62051423,  0.79181683, ..., -0.15949071,\n",
              "         1.24952158, -0.198591  ],\n",
              "       [-1.31421253, -0.02545202,  0.17222962, ..., -1.17923013,\n",
              "         1.00633824,  0.78861725],\n",
              "       ...,\n",
              "       [-2.0422935 , -1.09450351,  1.62437353, ..., -0.79868432,\n",
              "         0.12601173, -1.25066615],\n",
              "       [-0.33245315, -1.06787428, -0.25207701, ..., -0.42071348,\n",
              "         0.82034487,  1.27256459],\n",
              "       [ 0.68364172,  1.513437  ,  1.02388662, ..., -0.39449548,\n",
              "        -0.58930248, -0.0037248 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sketch_b['VA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP3QT1hfdAHm"
      },
      "source": [
        "**Approximate matrix multiplication**\n",
        "\n",
        "After generation of sketches from A and B, we will take the outerproduct of the common indices and then generate an approximate form of the original matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM0dXBsU9Tsc"
      },
      "outputs": [],
      "source": [
        "def approximate_matrix_multiplication(sketch_A, sketch_B):\n",
        "    # fnding common indieces between both the matrices\n",
        "    common_indices = np.intersect1d(sketch_A['IA'], sketch_B['IA'])\n",
        "\n",
        "    #w=da*d_b\n",
        "    d_A = sketch_A['VA'].shape[1]\n",
        "    d_B = sketch_B['VA'].shape[1]\n",
        "    W = np.zeros((d_A, d_B))\n",
        "\n",
        "    for i in common_indices:\n",
        "#getting the common values\n",
        "        idx_A = np.where(sketch_A['IA'] == i)[0][0]\n",
        "        idx_B = np.where(sketch_B['IA'] == i)[0][0]\n",
        "\n",
        "        Ai = sketch_A['VA'][idx_A]\n",
        "        Bi = sketch_B['VA'][idx_B]\n",
        "        norm_Ai = np.linalg.norm(Ai) ** 2\n",
        "        norm_Bi = np.linalg.norm(Bi) ** 2\n",
        "        denom = min(1, norm_Ai / sketch_A['ta'], norm_Bi / sketch_B['ta'])\n",
        "\n",
        "\n",
        "        # outer product of the common rows\n",
        "        W += np.outer(Ai, Bi.T) / denom\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMQiGCIGB0uF"
      },
      "outputs": [],
      "source": [
        "W = approximate_matrix_multiplication(sketch_a, sketch_b)\n",
        "w_norm=np.linalg.norm(W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v54Y7cBrnIcR",
        "outputId": "742218d1-2508-432c-ea3b-e2af0f694921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sketch_a['VA'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scD6mfw2nNIe",
        "outputId": "cbf00a42-2d4a-4a85-9076-f27541983b9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sketch_b['VA'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cVpDc-JnE67",
        "outputId": "4edac8a1-7b31-4b48-821c-53809fcf6ffa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "W.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2AeuNE1HVnN"
      },
      "outputs": [],
      "source": [
        "original_mul=A@B.T\n",
        "norm_original=np.linalg.norm(original_mul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOAW8-RuKP19",
        "outputId": "349eaf63-dcf3-4e99-d1c7-ef89bdf6b524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "950071.6519916842\n"
          ]
        }
      ],
      "source": [
        "#getting the error from original vs approximate\n",
        "error=norm_original-w_norm\n",
        "print(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcxCN8yupf7D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "\n",
        "# Compute the original matrix multiplication\n",
        "ATB = np.dot(A.T, B)\n",
        "norm_original = np.linalg.norm(A, 'fro') * np.linalg.norm(B, 'fro')\n",
        "\n",
        "k_values = [200, 400, 600, 800, 1000]\n",
        "errors = []\n",
        "\n",
        "for k in k_values:\n",
        "    # Sketch matrices A and B\n",
        "    sketch_A = coordinated_sampling(A, k)\n",
        "    sketch_B = coordinated_sampling(B, k)\n",
        "\n",
        "    # Compute the approximate multiplication using sketched matrices\n",
        "    W = approximate_matrix_multiplication(sketch_A, sketch_B)\n",
        "\n",
        "    # Compute the relative error wrt the original matrix\n",
        "    error_iteration = np.linalg.norm(W - ATB, 'fro') / norm_original\n",
        "    errors.append(error_iteration)\n",
        "\n",
        "# Plot the error vs. sketch size\n",
        "plt.plot(k_values, errors, marker='o', label='Coordinated Sampling')\n",
        "plt.xlabel('Sketch Size (k)')\n",
        "plt.ylabel('Relative Error')\n",
        "plt.title('Relative Error vs Sketch Size')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4bTRLmok5V-"
      },
      "outputs": [],
      "source": [
        "#the jl-lemma\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "\n",
        "# Apply random projection to reduce dimensionality\n",
        "transformer = GaussianRandomProjection(n_components=50)\n",
        "A_reduced = transformer.fit_transform(A)\n",
        "B_reduced = transformer.fit_transform(B)\n",
        "\n",
        "# Approximate matrix multiplication\n",
        "W_approx = np.dot(A_reduced, B_reduced.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwEbXeOblYd2"
      },
      "outputs": [],
      "source": [
        "W_approx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCJ1nagylCiP"
      },
      "outputs": [],
      "source": [
        "norm_original = np.linalg.norm(ATB, 'fro')\n",
        "\n",
        "n_components = [20, 40, 60, 80, 100]\n",
        "error = []\n",
        "\n",
        "for i in range(len(k_values)):\n",
        "    transformer = GaussianRandomProjection(n_components=50)\n",
        "    A_reduced = transformer.fit_transform(A)\n",
        "    B_reduced = transformer.fit_transform(B)\n",
        "\n",
        "# Approximate matrix multiplication\n",
        "    W_approx = np.dot(A_reduced, B_reduced.T)\n",
        "    error_iteration = np.linalg.norm(ATB - W_approx, 'fro') / norm_original\n",
        "    error.append(error_iteration)\n",
        "plt.plot(k_values, error)\n",
        "plt.xlabel('reduced dimensions')\n",
        "plt.ylabel('Relative Error')\n",
        "plt.title('Relative Error vs dimensional representation for JL lemma')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egBcEhyGoQqI"
      },
      "source": [
        "**Checking the performance of Coordianted sampling over sparse matrices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFWFldd7hJMy"
      },
      "outputs": [],
      "source": [
        "#code to get the sparse matrices in generated by CHATGPT\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "def generate_different_sparse_matrices(m, n, sparsity, outlier_ratio=0.1):\n",
        "    \"\"\"Generate two independent sparse matrices A and B with different sparsity patterns and values.\"\"\"\n",
        "\n",
        "    size = m * n\n",
        "    num_nonzeros = int((1 - sparsity) * size)  # Number of nonzero elements\n",
        "\n",
        "    # Generate independent values for A and B\n",
        "    values_A = np.random.randn(num_nonzeros)  # Normal distribution\n",
        "    values_B = np.random.uniform(-1, 1, num_nonzeros)  # Uniform distribution\n",
        "\n",
        "    # Introduce outliers differently for A and B\n",
        "    num_outliers = int(outlier_ratio * num_nonzeros)\n",
        "\n",
        "    outlier_indices_A = np.random.choice(num_nonzeros, num_outliers, replace=False)\n",
        "    outlier_indices_B = np.random.choice(num_nonzeros, num_outliers, replace=False)\n",
        "\n",
        "    values_A[outlier_indices_A] *= 10  # Outliers in A\n",
        "    values_B[outlier_indices_B] *= 5   # Outliers in B (different scaling)\n",
        "\n",
        "    # Ensure independent sparsity patterns\n",
        "    indices_A = np.random.choice(size, num_nonzeros, replace=False)\n",
        "    indices_B = np.random.choice(size, num_nonzeros, replace=False)\n",
        "\n",
        "    row_indices_A = indices_A // n\n",
        "    col_indices_A = indices_A % n\n",
        "\n",
        "    row_indices_B = indices_B // n\n",
        "    col_indices_B = indices_B % n\n",
        "\n",
        "    # Create two independent sparse matrices\n",
        "    sparse_A = coo_matrix((values_A, (row_indices_A, col_indices_A)), shape=(m, n))\n",
        "    sparse_B = coo_matrix((values_B, (row_indices_B, col_indices_B)), shape=(m, n))\n",
        "\n",
        "    return sparse_A, sparse_B\n",
        "\n",
        "# Example: Generate 1000x1000 sparse matrices with 10%, 40%, and 80% sparsity\n",
        "m, n = 1000, 1000\n",
        "sparse_10_a, sparse_10_b = generate_different_sparse_matrices(m, n, 0.10)\n",
        "sparse_40_a, sparse_40_b = generate_different_sparse_matrices(m, n, 0.40)\n",
        "sparse_80_a, sparse_80_b = generate_different_sparse_matrices(m, n, 0.80)\n",
        "\n",
        "# Convert to dense format\n",
        "dense_matrix_1 = sparse_10_a.toarray()\n",
        "dense_matrix_2 = sparse_10_b.toarray()\n",
        "dense_matrix_40_1 = sparse_40_a.toarray()\n",
        "dense_matrix_40_2 = sparse_40_b.toarray()\n",
        "dense_matrix_80_1 = sparse_80_a.toarray()\n",
        "dense_matrix_80_2 = sparse_80_b.toarray()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6veRUI3qkd1"
      },
      "source": [
        "Now that we have matrices which are 10% sparse, 40% sparse and 80% sparse. The next step is to compare the relative error between the approximate matrix multiplication for JL lemma and Coordinated sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOgw9QJOqjQw"
      },
      "outputs": [],
      "source": [
        "#first plot\n",
        "ATB = np.dot(dense_matrix_1.T, dense_matrix_2)\n",
        "norm_original = np.linalg.norm(ATB, 'fro')\n",
        "\n",
        "k = [200, 400, 600, 800, 1000]\n",
        "error_jl = []\n",
        "error_cs=[]\n",
        "\n",
        "for i in range(len(k)):\n",
        "    sketch_a = coordinated_sampling(dense_matrix_1, k[i])\n",
        "    sketch_b = coordinated_sampling(dense_matrix_2, k[i])\n",
        "    transformer = GaussianRandomProjection(n_components=k[i])\n",
        "    A_reduced = transformer.fit_transform(dense_matrix_1)\n",
        "    B_reduced = transformer.fit_transform(dense_matrix_2)\n",
        "\n",
        "# Approximate matrix multiplication\n",
        "    W_approx = np.dot(A_reduced, B_reduced.T)\n",
        "    error_iteration_jl = np.linalg.norm(ATB - W_approx, 'fro') / norm_original\n",
        "    error_jl.append(error_iteration_jl)\n",
        "    W = approximate_matrix_multiplication(sketch_a, sketch_b)\n",
        "    error_iteration_cs = np.linalg.norm(ATB - W, 'fro') / norm_original\n",
        "    error_cs.append(error_iteration_cs)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(k, error_jl, marker='s', linestyle='-', label=\"JL Sketch\", color=\"blue\")\n",
        "plt.plot(k, error_cs, marker='o', linestyle='-', label=\"Priority Sampling\", color=\"red\")\n",
        "\n",
        "plt.xlabel(\"Sketch Size\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Relative Error vs Sketch Size\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUq4NB-Bj8dm"
      },
      "outputs": [],
      "source": [
        "#first plot\n",
        "ATB = np.dot(dense_matrix_1.T, dense_matrix_2)\n",
        "norm_original = np.linalg.norm(ATB, 'fro')\n",
        "\n",
        "k = [200, 400, 600, 800, 1000]\n",
        "error_jl = []\n",
        "error_cs=[]\n",
        "\n",
        "for i in range(len(k)):\n",
        "    sketch_a = coordinated_sampling(dense_matrix_40_1, k[i])\n",
        "    sketch_b = coordinated_sampling(dense_matrix_40_2, k[i])\n",
        "    transformer = GaussianRandomProjection(n_components=k[i])\n",
        "    A_reduced = transformer.fit_transform(dense_matrix_1)\n",
        "    B_reduced = transformer.fit_transform(dense_matrix_2)\n",
        "\n",
        "# Approximate matrix multiplication\n",
        "    W_approx = np.dot(A_reduced, B_reduced.T)\n",
        "    error_iteration_jl = np.linalg.norm(ATB - W_approx, 'fro') / norm_original\n",
        "    error_jl.append(error_iteration_jl)\n",
        "    W = approximate_matrix_multiplication(sketch_a, sketch_b)\n",
        "    error_iteration_cs = np.linalg.norm(ATB - W, 'fro') / norm_original\n",
        "    error_cs.append(error_iteration_cs)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(k, error_jl, marker='s', linestyle='-', label=\"JL Sketch\", color=\"blue\")\n",
        "plt.plot(k, error_cs, marker='o', linestyle='-', label=\"Priority Sampling\", color=\"red\")\n",
        "\n",
        "plt.xlabel(\"Sketch Size\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Relative Error vs Sketch Size\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUzi7A8xkL8x"
      },
      "outputs": [],
      "source": [
        "#first plot\n",
        "ATB = np.dot(dense_matrix_1.T, dense_matrix_2)\n",
        "norm_original = np.linalg.norm(ATB, 'fro')\n",
        "\n",
        "k = [200, 400, 600, 800, 1000]\n",
        "error_jl = []\n",
        "error_cs=[]\n",
        "\n",
        "for i in range(len(k)):\n",
        "    sketch_a = coordinated_sampling(dense_matrix_80_1, k[i])\n",
        "    sketch_b = coordinated_sampling(dense_matrix_80_2, k[i])\n",
        "    transformer = GaussianRandomProjection(n_components=k[i])\n",
        "    A_reduced = transformer.fit_transform(dense_matrix_1)\n",
        "    B_reduced = transformer.fit_transform(dense_matrix_2)\n",
        "\n",
        "# Approximate matrix multiplication\n",
        "    W_approx = np.dot(A_reduced, B_reduced.T)\n",
        "    error_iteration_jl = np.linalg.norm(ATB - W_approx, 'fro') / norm_original\n",
        "    error_jl.append(error_iteration_jl)\n",
        "    W = approximate_matrix_multiplication(sketch_a, sketch_b)\n",
        "    error_iteration_cs = np.linalg.norm(ATB - W, 'fro') / norm_original\n",
        "    error_cs.append(error_iteration_cs)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(k, error_jl, marker='s', linestyle='-', label=\"JL Sketch\", color=\"blue\")\n",
        "plt.plot(k, error_cs, marker='o', linestyle='-', label=\"Priority Sampling\", color=\"red\")\n",
        "\n",
        "plt.xlabel(\"Sketch Size\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Relative Error vs Sketch Size\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiF6t8Pjbcpk"
      },
      "source": [
        "**Sketching Regression**\n",
        "\n",
        "Using coordinate sampling described in the paper to the regression problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csAwcnQzeczY"
      },
      "source": [
        "Coordinated sampling algortihm using leverage scores for the matrix A and b where they represent the standard sentiment forms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmCbCi0Hecah"
      },
      "outputs": [],
      "source": [
        "def sketch_regression(A,b,seed,error):\n",
        "  n,d=A.shape\n",
        "  #fixes the indexing issues\n",
        "  sample_size=(int(d/error)-1)\n",
        "  random.seed(seed)\n",
        "  h=np.random.uniform(0, 1, size=n)\n",
        "  mul=np.linalg.inv(A.T@A)\n",
        "  l=[]\n",
        "  i_a=[]\n",
        "  v_a=[]\n",
        "  r=np.empty(n)\n",
        "  for i in range(max(n,d)):\n",
        "    l_i=A[i]@mul@A[i].T\n",
        "    l.append(l_i)\n",
        "    r_i=h[i]/l[i]\n",
        "    r[i]=r_i\n",
        "  r_sorted=np.sort(r)\n",
        "  threshold=r_sorted[sample_size]\n",
        "  for i in range(n):\n",
        "        if r[i] < threshold:\n",
        "            i_a.append(i)\n",
        "            v_a.append(A[i])\n",
        "  sketch_A = {\n",
        "        'IA': np.array(i_a),\n",
        "        'VA': np.array(v_a),\n",
        "        'ta': threshold\n",
        "    }\n",
        "\n",
        "  sketch_b=coordinated_sampling(b.reshape(-1,1),sample_size)\n",
        "  return sketch_A,sketch_b, mul\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzUcnVZ2IgQo"
      },
      "outputs": [],
      "source": [
        "def approximate_regression(sketch_A, sketch_b,mul):\n",
        "  common_indices = np.intersect1d(sketch_A['IA'], sketch_b['IA'])\n",
        "  d_A = sketch_A['VA'].shape[1]\n",
        "  d_B = sketch_b['VA'].shape[1]\n",
        "  W = np.zeros((d_A, d_B))\n",
        "  for i in common_indices:\n",
        "#getting the common values\n",
        "   idx_A = np.where(sketch_A['IA'] == i)[0][0]\n",
        "   idx_B = np.where(sketch_b['IA'] == i)[0][0]\n",
        "#finding the common eleme ts\n",
        "   Ai = sketch_A['VA'][idx_A]\n",
        "   Bi = sketch_b['VA'][idx_B]\n",
        "   leverage_score=Ai@mul@Ai.T\n",
        "   norm_Bi = np.linalg.norm(Bi) ** 2\n",
        "   denom = min(1, leverage_score / sketch_A['ta'], norm_Bi / sketch_b['ta'])\n",
        "#getting the weight matrix\n",
        "   W += np.outer(Ai, Bi) / denom\n",
        "   #getting the approximated values\n",
        "   x = mul @ W\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0-JOu2rLkx1"
      },
      "source": [
        "Testing this on two random matrices A and B created synthetically using chatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsj2rN6FLj9l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set dimensions\n",
        "n, d = 100, 10  # 100 samples, 10 features\n",
        "\n",
        "# Generate random A matrix with values from a normal distribution\n",
        "A = np.random.randn(n, d)\n",
        "\n",
        "# Generate a random coefficient vector\n",
        "true_x = np.random.randn(d)\n",
        "\n",
        "# Generate b with some noise\n",
        "b = A @ true_x + np.random.randn(n) * 0.1  # Adding small noise\n",
        "\n",
        "# Print dimensions for verification\n",
        "print(\"A shape:\", A.shape)\n",
        "print(\"b shape:\", b.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GalLVXMBLwWu"
      },
      "outputs": [],
      "source": [
        "sketch_a,sketch_b,mul=sketch_regression(A,b,42,0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVSA7OVuOiOQ"
      },
      "outputs": [],
      "source": [
        "print(sketch_a['VA'].shape)\n",
        "print(sketch_b['VA'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6I9mYNIOA-S"
      },
      "outputs": [],
      "source": [
        "x_star=approximate_regression(sketch_a,sketch_b,mul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8NywpESBQr"
      },
      "outputs": [],
      "source": [
        "b_pred=A@x_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-COJzHMSU-b"
      },
      "outputs": [],
      "source": [
        "print(b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlfZ8Ep4SJuw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "display = PredictionErrorDisplay(y_true=b.reshape(-1,1), y_pred=b_pred)\n",
        "display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVNroQ7WSwLQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_regression_fit(b, b_pred):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Scatter plot of actual values\n",
        "    plt.scatter(range(len(b)), b, color='blue', label='Actual Values', alpha=0.6)\n",
        "\n",
        "    # Line plot of predicted values\n",
        "    plt.plot(range(len(b_pred)), b_pred, color='red', label='Predicted Values', linewidth=2)\n",
        "\n",
        "    plt.xlabel(\"Data Point Index\")\n",
        "    plt.ylabel(\"Target Value\")\n",
        "    plt.title(\"Actual vs. Predicted Values\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_regression_fit(b, b_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKc0kWu7S5im"
      },
      "source": [
        "**Using the IMDB dataset to check for anomlaies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMXBjYJAS5Oo"
      },
      "outputs": [],
      "source": [
        "#loading the data\n",
        "import kagglehub\n",
        "import os\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "print(os.listdir(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Oy50avmTh_t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "csv_file_path = os.path.join(path, \"IMDB Dataset.csv\")\n",
        "df = pd.read_csv(csv_file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcOfg1sKV-zP"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV1VdgqVVY8B"
      },
      "outputs": [],
      "source": [
        "x=df['review']\n",
        "y=df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2q-eWzEW5Oo"
      },
      "outputs": [],
      "source": [
        "y.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghuvZvvzVkMu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=512)\n",
        "X_tfidf = vectorizer.fit_transform(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2t3P9EcWjr5"
      },
      "outputs": [],
      "source": [
        "x_array=X_tfidf.toarray()\n",
        "print(x_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-lAhkiyW8qF"
      },
      "outputs": [],
      "source": [
        "y = y.map({'positive': 1, 'negative': 0})  # Convert to binary (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDfDcAQyXNsT"
      },
      "outputs": [],
      "source": [
        "y=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wBlJjIJXZgS"
      },
      "outputs": [],
      "source": [
        "print(x_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CinNyAsLxJ0-"
      },
      "outputs": [],
      "source": [
        "hash = np.random.uniform(0, 1, size=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuL43IKwW_U3"
      },
      "outputs": [],
      "source": [
        "sketch_a,sketch_b,mul=sketch_regression(x_array,y,42,0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_uk-AvWXuXj"
      },
      "outputs": [],
      "source": [
        "x_star=approximate_regression(sketch_a,sketch_b,mul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxhdOw7_X0f2"
      },
      "outputs": [],
      "source": [
        "y_pred=x_array@x_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN-CzVLlYVuQ"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = 1 / (1 + np.exp(-(y_pred)))\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muh-wNLRaG-c"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnNbR6qTZ-bJ"
      },
      "source": [
        "The code below is generated by CHATGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EH0pk6SY0_Z"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Step 2: Compute Confusion Matrix\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "# Step 3: Visualize Confusion Matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"Actual Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Print Classification Report (Accuracy, Precision, Recall, F1)\n",
        "print(classification_report(y, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irT7g18OyXEK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute Euclidean norm (L2 norm) and relative error\n",
        "error_norm = np.linalg.norm(y_pred - y)\n",
        "relative_error = error_norm / np.linalg.norm(y)\n",
        "\n",
        "# Plot the differences\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y, label=\"Optimal y\", color=\"green\")\n",
        "plt.plot(y_pred, label=\"Predicted y\", linestyle=\"dashed\", color=\"blue\")\n",
        "plt.plot(y - y_pred, label=\"Difference\", color=\"red\")\n",
        "plt.title(\"Comparison of y_pred vs y_optimal\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}