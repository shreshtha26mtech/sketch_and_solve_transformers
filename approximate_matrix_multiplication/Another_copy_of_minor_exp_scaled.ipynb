{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.fft import fft\n",
        "import pandas as pd\n",
        "from scipy.linalg import orth\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "import time\n"
      ],
      "metadata": {
        "id": "hqOS9dVdrsxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The class to generate the matrices.\n",
        "class MatrixGeneration:\n",
        "\n",
        "  \"\"\"\n",
        "    The MatrixGeneration class takes three arguments in the constructor.\n",
        "\n",
        "    m: The number of rows.\n",
        "    n: The number of cols.\n",
        "    kappa: How \"bad\" or \"ill-mannered\" the matrix is. A lower value of kappa means the matrix is clean, meaning multiplying does not amplify errors.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,m,n,kappa):\n",
        "    self.m=m\n",
        "    self.n=n\n",
        "    self.kappa=kappa\n",
        "\n",
        "    ## TODO: Some places we return self.A, some places we return A.lets make it uniform.\n",
        "    #matrices with good condition number\n",
        "  def ug_matrix(self):\n",
        "    U = orth(np.random.rand(self.m, self.n))   # m x n orthonormal matrix\n",
        "    V = orth(np.random.rand(self.n, self.n))   # n x n orthonormal matrix\n",
        "    S = np.diag(np.linspace(1, 1/self.kappa, self.n))  # Diagonal scaling matrix\n",
        "    self.A = U @ S @ V   # Final matrix\n",
        "    return self.A\n",
        "\n",
        "  #nb and ng matrices are the matrices which have a bad leverage score\n",
        "  def nb_matrix(self):\n",
        "      # Determine dimensions for constructing the matrix\n",
        "      half_num_cols = int(self.n / 2)\n",
        "      top_block_rows = self.m - half_num_cols\n",
        "\n",
        "      # Random Gaussian block\n",
        "      gaussian_block = np.random.normal(0, 1, (top_block_rows, half_num_cols))\n",
        "\n",
        "      # Tiny noise block\n",
        "      tiny_noise_block = 1e-8 * np.random.rand(top_block_rows, half_num_cols)\n",
        "\n",
        "      # Identity matrix for the stable part\n",
        "      identity_block = np.identity(half_num_cols)\n",
        "\n",
        "      # Construct matrix blocks\n",
        "      top_left = self.kappa * gaussian_block\n",
        "      top_right = tiny_noise_block\n",
        "      bottom_left = np.zeros((half_num_cols, top_block_rows))\n",
        "      bottom_right = identity_block\n",
        "\n",
        "      # Assemble full matrix\n",
        "      top_half = np.hstack([top_left, top_right])\n",
        "      bottom_half = np.hstack([bottom_left[:, :half_num_cols], bottom_right])\n",
        "      A = np.vstack([top_half, bottom_half])\n",
        "\n",
        "      return A\n"
      ],
      "metadata": {
        "id": "UuUSm2n3tHCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i0NaxlXrGrz"
      },
      "outputs": [],
      "source": [
        "class MatrixApproximationLeverage:\n",
        "    \"\"\"\n",
        "    Performs approximate matrix multiplication using leverage score sampling techniques.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def leverage_score_sampling(A: np.ndarray, B: np.ndarray, samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Selects rows from A and B based on leverage scores to approximate A @ B.T.\n",
        "\n",
        "        Args:\n",
        "            A (np.ndarray): Input matrix of shape (m, n)\n",
        "            B (np.ndarray): Input matrix of shape (n, p)\n",
        "            samples (int): Number of rows to sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.ndarray, np.ndarray]: Scaled sampled matrices A' and B'\n",
        "        \"\"\"\n",
        "        m, _ = A.shape\n",
        "        _, p = B.shape\n",
        "\n",
        "        U, _, _ = np.linalg.svd(A, full_matrices=False)\n",
        "        U_b, _, _ = np.linalg.svd(B, full_matrices=False)\n",
        "\n",
        "        leverage_scores_A = np.sum(U**2, axis=1)\n",
        "        leverage_scores_B = np.sum(U_b**2, axis=1)\n",
        "\n",
        "        top_A = np.argpartition(leverage_scores_A, -samples)[-samples:]\n",
        "        top_B = np.argpartition(leverage_scores_B, -samples)[-samples:]\n",
        "\n",
        "        sampled_A = A[top_A, :]\n",
        "        sampled_B = B[top_B, :]\n",
        "\n",
        "        scaled_A = sampled_A * np.sqrt(A.shape[0] / samples)\n",
        "        scaled_B = sampled_B * np.sqrt(B.shape[1] / samples)\n",
        "\n",
        "        return scaled_A, scaled_B\n",
        "\n",
        "    @staticmethod\n",
        "    def sqrt_leverage_score_sampling(A: np.ndarray, B: np.ndarray, samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Selects rows using the square root of leverage scores.\n",
        "\n",
        "        Args:\n",
        "            A (np.ndarray): Input matrix of shape (m, n)\n",
        "            B (np.ndarray): Input matrix of shape (n, p)\n",
        "            samples (int): Number of rows to sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.ndarray, np.ndarray]: Scaled sampled matrices A' and B'\n",
        "        \"\"\"\n",
        "\n",
        "        m, _ = A.shape\n",
        "        _, p = B.shape\n",
        "\n",
        "        U, _, _ = np.linalg.svd(A, full_matrices=False)\n",
        "        U_b, _, _ = np.linalg.svd(B, full_matrices=False)\n",
        "\n",
        "        leverage_scores_A = np.sqrt(np.sum(U**2, axis=1))\n",
        "        leverage_scores_B = np.sqrt(np.sum(U_b**2, axis=1))\n",
        "\n",
        "        top_A = np.argpartition(leverage_scores_A, -samples)[-samples:]\n",
        "        top_B = np.argpartition(leverage_scores_B, -samples)[-samples:]\n",
        "\n",
        "        sampled_A = A[top_A, :]\n",
        "        sampled_B = B[top_B, :]\n",
        "\n",
        "        scaled_A = sampled_A * np.sqrt(A.shape[0] / samples)\n",
        "        scaled_B = sampled_B * np.sqrt(B.shape[1] / samples)\n",
        "\n",
        "        return scaled_A, scaled_B\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "class MatrixApproximationSampling:\n",
        "    def __init__(self, hash_size: int = 10000, seed: int = 42):\n",
        "        \"\"\"\n",
        "        Initializes the sampler with a random hash vector used for priority and threshold sampling.\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        self.hash = np.random.uniform(0, 1, size=hash_size)\n",
        "\n",
        "    def uniform_sampling(self, A: np.ndarray, B: np.ndarray, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Uniformly samples columns from A and corresponding rows from B.T.\n",
        "\n",
        "        Returns two matrices C and R such that C @ R ≈ A @ B.T\n",
        "        \"\"\"\n",
        "        m, n_A = A.shape\n",
        "        n_B, p = B.T.shape\n",
        "\n",
        "        if n_A != n_B:\n",
        "            raise ValueError(\"Incompatible shapes: A.columns must match B.rows for multiplication\")\n",
        "\n",
        "        C = np.zeros((m, num_samples))\n",
        "        R = np.zeros((num_samples, p))\n",
        "\n",
        "        for t in range(num_samples):\n",
        "            idx = np.random.choice(n_A)\n",
        "            scaling = np.sqrt(n_A / num_samples)\n",
        "            C[:, t] = A[:, idx] * scaling\n",
        "            R[t, :] = B.T[idx, :] * scaling\n",
        "\n",
        "        return C, R\n",
        "\n",
        "    def priority_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Performs priority sampling on the rows of matrix A.\n",
        "\n",
        "        Returns a sketch with selected row indices, row values, and a threshold.\n",
        "        \"\"\"\n",
        "        n, d = A.shape\n",
        "        r = np.full(n, np.inf)\n",
        "\n",
        "        for i in range(n):\n",
        "            norm_sq = np.linalg.norm(A[i]) ** 2\n",
        "            if norm_sq > 0:\n",
        "                r[i] = self.hash[i] / norm_sq\n",
        "\n",
        "        threshold = np.partition(r, num_samples)[num_samples] if num_samples < n else np.inf\n",
        "\n",
        "        selected_indices = np.where(r < threshold)[0]\n",
        "        selected_rows = A[selected_indices]\n",
        "\n",
        "        return {\n",
        "            'indices': selected_indices,\n",
        "            'values': selected_rows,\n",
        "            'threshold': threshold\n",
        "        }\n",
        "\n",
        "    def threshold_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Performs threshold sampling based on row norms and a hash function.\n",
        "\n",
        "        Returns a sketch with selected row indices, row values, and a threshold value.\n",
        "        \"\"\"\n",
        "        n, d = A.shape\n",
        "        A_norm_sq = np.linalg.norm(A, 'fro') ** 2\n",
        "        tau = num_samples / A_norm_sq if A_norm_sq > 0 else float('inf')\n",
        "\n",
        "        selected_indices = []\n",
        "        selected_rows = []\n",
        "\n",
        "        for i in range(n):\n",
        "            row_norm_sq = np.linalg.norm(A[i]) ** 2\n",
        "            if self.hash[i] <= tau * row_norm_sq:\n",
        "                selected_indices.append(i)\n",
        "                selected_rows.append(A[i])\n",
        "\n",
        "        return {\n",
        "            'indices': np.array(selected_indices),\n",
        "            'values': np.array(selected_rows),\n",
        "            'threshold': tau\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def approximate_matrix_multiplication(sketch_A: Dict[str, Any], sketch_B: Dict[str, Any]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Approximates matrix multiplication using row sketches.\n",
        "\n",
        "        Only uses rows that are common to both A and B sketches.\n",
        "        \"\"\"\n",
        "        indices_A = sketch_A['indices']\n",
        "        indices_B = sketch_B['indices']\n",
        "        common_indices = np.intersect1d(indices_A, indices_B)\n",
        "\n",
        "        if common_indices.size == 0:\n",
        "            return np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
        "\n",
        "        result = np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
        "\n",
        "        for idx in common_indices:\n",
        "            i_A = np.where(indices_A == idx)[0][0]\n",
        "            i_B = np.where(indices_B == idx)[0][0]\n",
        "\n",
        "            row_A = sketch_A['values'][i_A]\n",
        "            row_B = sketch_B['values'][i_B]\n",
        "\n",
        "            norm_A = np.linalg.norm(row_A) ** 2\n",
        "            norm_B = np.linalg.norm(row_B) ** 2\n",
        "            denom = min(1.0, norm_A / sketch_A['threshold'], norm_B / sketch_B['threshold'])\n",
        "\n",
        "            if denom > 0:\n",
        "                result += np.outer(row_A, row_B) / denom\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "GIwkGKk_rujF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixApproximationSampling:\n",
        "    def __init__(self, hash_size: int = 10000, seed: int = 42):\n",
        "        \"\"\"\n",
        "        Initializes the sampler with a random hash vector used for priority and threshold sampling.\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        self.hash = np.random.uniform(0, 1, size=hash_size)\n",
        "         def uniform_sampling(self, A: np.ndarray, B: np.ndarray, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Uniformly samples columns from A and corresponding rows from B.T.\n",
        "\n",
        "        Returns two matrices C and R such that C @ R ≈ A @ B.T\n",
        "        \"\"\"\n",
        "        m, n_A = A.shape\n",
        "        n_B, p = B.T.shape\n",
        "\n",
        "        if n_A != n_B:\n",
        "            raise ValueError(\"Incompatible shapes: A.columns must match B.rows for multiplication\")\n",
        "\n",
        "        C = np.zeros((m, num_samples))\n",
        "        R = np.zeros((num_samples, p))\n",
        "\n",
        "        for t in range(num_samples):\n",
        "            idx = np.random.choice(n_A)\n",
        "            scaling = np.sqrt(n_A / num_samples)\n",
        "            C[:, t] = A[:, idx] * scaling\n",
        "            R[t, :] = B.T[idx, :] * scaling\n",
        "\n",
        "        return C, R\n",
        "\n",
        "\n",
        "    def priority_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Performs priority sampling on the rows of matrix A.\n",
        "\n",
        "        Returns a sketch with selected row indices, row values, and a threshold.\n",
        "        \"\"\"\n",
        "        n, d = A.shape\n",
        "        r = np.full(n, np.inf)\n",
        "\n",
        "        for i in range(n):\n",
        "            norm_sq = np.linalg.norm(A[i]) ** 2\n",
        "            if norm_sq > 0:\n",
        "                r[i] = self.hash[i] / norm_sq\n",
        "\n",
        "        threshold = np.partition(r, num_samples)[num_samples] if num_samples < n else np.inf\n",
        "\n",
        "        selected_indices = np.where(r < threshold)[0]\n",
        "        selected_rows = A[selected_indices]\n",
        "\n",
        "        return {\n",
        "            'indices': selected_indices,\n",
        "            'values': selected_rows,\n",
        "            'threshold': threshold\n",
        "        }\n",
        "\n",
        "    def threshold_sampling(self, A: np.ndarray, num_samples: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Performs threshold sampling based on row norms and a hash function.\n",
        "\n",
        "        Returns a sketch with selected row indices, row values, and a threshold value.\n",
        "        \"\"\"\n",
        "        n, d = A.shape\n",
        "        A_norm_sq = np.linalg.norm(A, 'fro') ** 2\n",
        "        tau = num_samples / A_norm_sq if A_norm_sq > 0 else float('inf')\n",
        "\n",
        "        selected_indices = []\n",
        "        selected_rows = []\n",
        "\n",
        "        for i in range(n):\n",
        "            row_norm_sq = np.linalg.norm(A[i]) ** 2\n",
        "            if self.hash[i] <= tau * row_norm_sq:\n",
        "                selected_indices.append(i)\n",
        "                selected_rows.append(A[i])\n",
        "\n",
        "        return {\n",
        "            'indices': np.array(selected_indices),\n",
        "            'values': np.array(selected_rows),\n",
        "            'threshold': tau\n",
        "        }\n",
        "    @staticmethod\n",
        "    def approximate_matrix_multiplication(sketch_A: Dict[str, Any], sketch_B: Dict[str, Any]) -> np.ndarray:\n",
        "      \"\"\"\n",
        "      Approximates matrix multiplication using row sketches.\n",
        "      Only uses rows that are common to both A and B sketches.\n",
        "      \"\"\"\n",
        "      indices_A = sketch_A['indices']\n",
        "      indices_B = sketch_B['indices']\n",
        "      common_indices = np.intersect1d(indices_A, indices_B)\n",
        "\n",
        "      if common_indices.size == 0:\n",
        "          return np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
        "\n",
        "      result = np.zeros((sketch_A['values'].shape[1], sketch_B['values'].shape[1]))\n",
        "\n",
        "      for idx in common_indices:\n",
        "          i_A = np.where(indices_A == idx)[0][0]\n",
        "          i_B = np.where(indices_B == idx)[0][0]\n",
        "\n",
        "          row_A = sketch_A['values'][i_A]\n",
        "          row_B = sketch_B['values'][i_B]\n",
        "\n",
        "          norm_A = np.linalg.norm(row_A) ** 2\n",
        "          norm_B = np.linalg.norm(row_B) ** 2\n",
        "          # CORRECTED: Multiply by thresholds instead of dividing\n",
        "          denom = min(1.0, norm_A * sketch_A['threshold'], norm_B * sketch_B['threshold'])\n",
        "\n",
        "          if denom > 0:\n",
        "              result += np.outer(row_A, row_B) / denom\n",
        "\n",
        "      return result"
      ],
      "metadata": {
        "id": "uP-J6d_KNFv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JLemma:\n",
        "\n",
        "  def gaussian_JL(self,A,B,samples):\n",
        "    m, n = A.shape\n",
        "    _, p = B.shape\n",
        "    R = np.random.normal(0, 1/np.sqrt(samples), size=(samples, n))\n",
        "    A_proj = A @ R.T\n",
        "    B_proj = R @ B.T\n",
        "    approx_product = A_proj @ B_proj\n",
        "    return approx_product\n",
        "  def PHD_JL(self,A,B,samples):\n",
        "        m, n = A.shape\n",
        "        _, p = B.shape\n",
        "        D = np.diag(np.random.choice([-1, 1], size=n))\n",
        "        H = fft(np.eye(n), norm='ortho')\n",
        "        P = np.zeros((samples, n))\n",
        "        selected_rows = np.random.choice(n,samples)\n",
        "        P[np.arange(samples), selected_rows] = 1\n",
        "        Phi = P @ H @ D\n",
        "        A_proj = A @ Phi.T\n",
        "        B_proj = Phi @ B.T\n",
        "        approx_product = A_proj @ B_proj\n",
        "        return approx_product\n"
      ],
      "metadata": {
        "id": "g95KV4NWsrrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.fftpack import fft\n",
        "\n",
        "class JLemma:\n",
        "    def gaussian_JL(self, A, B, samples):\n",
        "        \"\"\"Gaussian JL: Dense random projection with i.i.d. normal entries.\"\"\"\n",
        "        m, n = A.shape\n",
        "        _, p = B.shape\n",
        "        R = np.random.normal(0, 1/np.sqrt(samples), size=(samples, n))\n",
        "        A_proj = A @ R.T\n",
        "        B_proj = R @ B.T\n",
        "        approx_product = A_proj @ B_proj\n",
        "        return approx_product\n",
        "\n",
        "    def PHD_JL(self, A, B, samples):\n",
        "        \"\"\"PHD JL: Fast Johnson-Lindenstrauss using FFT and subsampling.\"\"\"\n",
        "        m, n = A.shape\n",
        "        _, p = B.shape\n",
        "        D = np.diag(np.random.choice([-1, 1], size=n))\n",
        "        H = fft(np.eye(n), norm='ortho')\n",
        "        P = np.zeros((samples, n))\n",
        "        selected_rows = np.random.choice(n, samples, replace=False)\n",
        "        P[np.arange(samples), selected_rows] = 1\n",
        "        Phi = P @ H @ D\n",
        "        A_proj = A @ Phi.T\n",
        "        B_proj = Phi @ B.T\n",
        "        approx_product = A_proj @ B_proj\n",
        "        return approx_product\n",
        "\n",
        "    def countsketch_JL(self, A, B, s):\n",
        "        \"\"\"\n",
        "        Count Sketch JL: Sparse projection using hashing and sign flipping.\n",
        "        Args:\n",
        "            A: (m x n) matrix\n",
        "            B: (p x n) matrix (must match A's columns)\n",
        "            s: sketch size (target dimension)\n",
        "        Returns:\n",
        "            Approximate product (A @ B.T) of shape (m x p)\n",
        "        \"\"\"\n",
        "        m, n = A.shape\n",
        "        p, _ = B.shape\n",
        "\n",
        "        # Generate hash functions and signs (shared for A and B)\n",
        "        h = np.random.randint(0, s, size=n)  # Hash buckets\n",
        "        sigma = np.random.choice([-1, 1], size=n)  # Random signs\n",
        "\n",
        "        # Compute A's sketch (m x s)\n",
        "        A_sketch = np.zeros((m, s))\n",
        "        for j in range(n):\n",
        "            A_sketch[:, h[j]] += sigma[j] * A[:, j]\n",
        "\n",
        "        # Compute B's sketch (s x p)\n",
        "        B_sketch = np.zeros((s, p))\n",
        "        for j in range(n):\n",
        "            B_sketch[h[j], :] += sigma[j] * B[:, j]\n",
        "\n",
        "        return A_sketch @ B_sketch"
      ],
      "metadata": {
        "id": "7NiDIOmMN50u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all the four matrices\n",
        "\"\"\"\n",
        "There are two key properties being considered here:\n",
        "\n",
        "1. Leverage Score Distribution\n",
        "Uniform leverage scores → all rows are equally “important”\n",
        "\n",
        "Non-uniform leverage scores → some rows are more “important” than others\n",
        "\n",
        "2. Condition Number (κ / kappa)\n",
        "Good condition number (low κ) → matrix is stable for computation\n",
        "\n",
        "Bad condition number (high κ) → matrix is numerically unstable, more sensitive to error\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Case 1: Good Condition Number (kappa = 1e-8)\n",
        "good_condition = MatrixGeneration(10000, 100, 1e-8)\n",
        "A_uniform_good = good_condition.ug_matrix()\n",
        "B_uniform_good = good_condition.ug_matrix()\n",
        "A_nonuniform_good = good_condition.nb_matrix()\n",
        "B_nonuniform_good = good_condition.nb_matrix()\n",
        "\n",
        "# Case 2: Bad Condition Number (kappa = 10)\n",
        "bad_condition = MatrixGeneration(10000, 100, 10)\n",
        "A_uniform_bad = bad_condition.ug_matrix()\n",
        "B_uniform_bad = bad_condition.ug_matrix()\n",
        "A_nonuniform_bad = bad_condition.nb_matrix()\n",
        "B_nonuniform_bad = bad_condition.nb_matrix()\n"
      ],
      "metadata": {
        "id": "uIkOLoVdloIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sizes = [250, 500, 750, 1000, 1250, 1500, 1750, 2000]\n",
        "iterations = 5\n",
        "\n",
        "matrix_types = [\n",
        "    (\"Uniform Good\", 1e-8, \"ug_matrix\"),\n",
        "    (\"Uniform Bad\", 10, \"ug_matrix\"),\n",
        "    (\"Non-uniform Good\", 1e-8, \"nb_matrix\"),\n",
        "    (\"Non-uniform Bad\", 10, \"nb_matrix\"),\n",
        "]\n"
      ],
      "metadata": {
        "id": "nYBjDgD-PA3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for matrix_name, kappa, gen_method in tqdm(matrix_types, desc=\"Matrix Types\"):\n",
        "    generator = MatrixGeneration(10000, 100, kappa)\n",
        "    A = getattr(generator, gen_method)()\n",
        "    B = getattr(generator, gen_method)()\n",
        "\n",
        "    original_product = A @ B.T\n",
        "    original_norm = np.linalg.norm(original_product, 'fro')\n",
        "\n",
        "    for size in sample_sizes:\n",
        "        for i in range(iterations):\n",
        "            # Each method result will be stored in its own row\n",
        "            def add_row(method_name, approx_matrix, duration):\n",
        "                approx_norm = np.linalg.norm(approx_matrix, 'fro')\n",
        "                rel_error = abs(original_norm - approx_norm) / original_norm\n",
        "                results.append({\n",
        "                    \"matrix\": matrix_name,\n",
        "                    \"sample_size\": size,\n",
        "                    \"iteration\": i + 1,\n",
        "                    \"method\": method_name,\n",
        "                    \"time\": duration,\n",
        "                    \"frobenius_norm\": approx_norm,\n",
        "                    \"relative_error\": rel_error\n",
        "                })\n",
        "\n",
        "            # Leverage Sampling\n",
        "            start = time.time()\n",
        "            S_a, S_b = MatrixApproximationLeverage.leverage_score_sampling(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Leverage Sampling\", S_a @ S_b.T, end - start)\n",
        "\n",
        "            # Sqrt Leverage\n",
        "            start = time.time()\n",
        "            S_a, S_b = MatrixApproximationLeverage.sqrt_leverage_score_sampling(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Sqrt Leverage Sampling\", S_a @ S_b.T, end - start)\n",
        "\n",
        "            # Priority Sampling\n",
        "            sampler = MatrixApproximationSampling()\n",
        "            start = time.time()\n",
        "            S_a = sampler.priority_sampling(A, size)\n",
        "            S_b = sampler.priority_sampling(B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Priority Sampling\", sampler.approximate_matrix_multiplication(S_a, S_b), end - start)\n",
        "\n",
        "            # Threshold Sampling\n",
        "            start = time.time()\n",
        "            S_a = sampler.threshold_sampling(A, size)\n",
        "            S_b = sampler.threshold_sampling(B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Threshold Sampling\", sampler.approximate_matrix_multiplication(S_a, S_b), end - start)\n",
        "\n",
        "            # Uniform Sampling\n",
        "            start = time.time()\n",
        "            S_a, S_b = sampler.uniform_sampling(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Uniform Sampling\", S_a @ S_b, end - start)\n",
        "\n",
        "            # Gaussian JL\n",
        "            lemma = JLemma()\n",
        "            start = time.time()\n",
        "            G = lemma.gaussian_JL(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"Gaussian JL\", G, end - start)\n",
        "\n",
        "            # PHD JL\n",
        "            start = time.time()\n",
        "            P = lemma.PHD_JL(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"PHD JL\", P, end - start)\n",
        "\n",
        "            #count-sketch JL\n",
        "            start = time.time()\n",
        "            C = lemma.countsketch_JL(A, B, size)\n",
        "            end = time.time()\n",
        "            add_row(\"countsketch JL\", C, end - start)\n",
        "\n",
        "\n",
        "# Save final results\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"matrix_experiment_results.csv\", index=False)\n",
        "print(\"CSV saved as matrix_experiment_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxpmj_I8Pf8M",
        "outputId": "ca010ddb-df49-4366-cf17-63db1da656ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Matrix Types: 100%|██████████| 4/4 [1:40:24<00:00, 1506.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as matrix_experiment_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}